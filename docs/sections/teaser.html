<!-- ---------- TEASER ---------- -->
<section class="teaser">
  <div class="container main-content-with-sidebar mt-6">
    <!-- <img src="./resources/teaser.gif" alt="Teaser" class="img-full"> -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <p class="content has-text-left">
          We present a novel post-training paradigm, Visual Game Learning or <strong>ViGaL</strong>, where MLLMs develop out-of-domain generalization of multimodal reasoning through playing arcade-like games.
          We show that after training a MLLM via reinforcement learning on simple arcade-like games like <a href="">Snake</a> significantly enhances its downstream performance on multimodal math benchmarks like <a href="">MathVista</a>,
          and on multi-discipline questions like <a href="">MMMU</a>,
          <strong><span style="color: green;">without seeing any worked solutions, equations, or diagrams during RL</span></strong>,
          suggesting the capture of transferable reasoning skills.
        </p>
        <p class="has-text-left">
          Our model outperforms specialist models tuned on multimodal reasoning data in multimodal reasoning benchmarks, while preserving the base modelâ€™s performance on general visual benchmarks, a challenge where specialist models often fall short.
          Our findings suggest a new post-training paradigm: synthetic, rule-based games can serve as controllable and scalable pre-text tasks that unlock <strong><span style="color: green;">generalizable multimodal reasoning abilities</span></strong>.
        </p>
        <img src="./resources/teaser_fig.png" alt="Teaser" class="img-responsive mt-6" style="width: 60%; height: auto;">
    </div>
  </div>
</section> 